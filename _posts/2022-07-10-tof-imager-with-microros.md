---
layout: post
title: PointCloud2 publisher with micro-ROS
subtitle: using a VL53L5CX ToF imaging sensor
gh-repo: adityakamath/arduino_sketchbook_ros
thumbnail-img: /assets/img/sensor_vl53l5cx_thumb.jpg
share-img: /assets/img/sensor_vl53l5cx_thumb.jpg
gh-badge: [follow]
comments: true
---

This week, I received some of the goodies I mentioned in the [last update](https://adityakamath.github.io/2022-07-02-even-more-microros-examples/). One of them (I'll talk about the other later) was the [Sparkfun Qwiic ToF Imager](https://www.sparkfun.com/products/18642) based on the [VL53L5CX](https://github.com/sparkfun/SparkFun_VL53L5CX_Arduino_Library/blob/main/documents/vl53l5cx.pdf) sensor by STMicroelectronics. It is a 8x8 time-of-flight (ToF) sensor (64 pixels), with a field-of-view of 45 degrees and a maximum range of 4 meters. It provides data on an I2C bus, at 15Hz for an 8x8 grid, and 60Hz for 4x4. The sensor also comes with additional features such as power modes and motion/reflectance indicators which allow it to detect glass up to 60cm. Since it uses I2C, multiple sensors can be linked to the same bus, which makes it an ideal sensor for robotics applications. More documentation can be found [here](https://github.com/sparkfun/SparkFun_VL53L5CX_Arduino_Library/blob/main/documents/um2887-software-integration-guide.pdf) and [here](https://github.com/sparkfun/SparkFun_VL53L5CX_Arduino_Library/blob/main/documents/um2884-a-guide-to-using-the-vl53l5cx.pdf). I immediately decided to start playing with it, and also decided to use it as an opportunity to implement a [micro-ROS](https://micro.ros.org/) application from scratch.

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/sensor_vl53l5cx_with_scale.jpg"/>
	<figcaption>The Sparkfun Qwiic ToF imager module, with the VL53L5CX sensor.
	</figcaption>
</figure>

First, I started off by installing the [Sparkfun VL53L5CX library](https://github.com/sparkfun/SparkFun_VL53L5CX_Arduino_Library) on the Arduino IDE and then loaded the some example sketches. Most of the examples use only the ToF capabilities, and result in a 8x8 ordered array of measured data, captured at 15Hz. This data is also formatted and written to the serial port. [One of the examples](https://github.com/sparkfun/SparkFun_VL53L5CX_Arduino_Library/blob/main/examples/Example4_MaxOutput/Example4_MaxOutput.ino) also comes with an accompanying [Processing](https://processing.org/) [app](https://github.com/sparkfun/SparkFun_VL53L5CX_Arduino_Library/blob/main/processingApp/SparkFun_VL53L5CX_3D_Depth_Map/SparkFun_VL53L5CX_3D_Depth_Map.pde) that visualizes the data points written to the serial port. Finally, after playing around with some settings, I ended up with a final Arduino + Processing example that configures, initializes and polls the sensor, and the resulting depth map is visualized by Processing.

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/sensor_vl53l5cx_processing_viz.PNG"/>
	<figcaption>Depth map visualized by the Processing app.
	</figcaption>
</figure>

### micro-ROS Pointcloud Publisher

The next step was to make a micro-ROS node. Since, I am using pre-compiled micro-ROS ([micro_ros_arduino v2.0.5-galactic](https://github.com/micro-ROS/micro_ros_arduino/releases/tag/v2.0.5-galactic)) libraries, I decided not to make a [custom message type](https://micro.ros.org/docs/tutorials/advanced/create_new_type/) (for now) and instead use the [PointCloud2](https://docs.ros2.org/galactic/api/sensor_msgs/msg/PointCloud2.html) (PCL2) message type, which is most commonly used with such sensors. Now, since the PCL2 message is huge in size, I decided to use devices that can handle the size (and speed) requirements. So, I decided to skip the [RP2040](https://en.wikipedia.org/wiki/RP2040) based devices, and chose the [Arduino Portenta](https://store.arduino.cc/products/portenta-h7). I also have a [Teensy 4.1](https://www.pjrc.com/store/teensy41.html) which should also support the communication of this message type, but I couldn't use it as I will explain later. First, I used the [Integer Publisher example](https://github.com/micro-ROS/micro_ros_arduino/blob/galactic/examples/micro-ros_publisher/micro-ros_publisher.ino) from [micro_ros_arduino](https://github.com/micro-ROS/micro_ros_arduino/tree/galactic), and added the VL53L5CX code from my earlier experiment. Since, we publish a PCL2 message, I had to change the publisher, so that it publishes a PointCloud2 instead of [UInt32](https://docs.ros2.org/galactic/api/std_msgs/msg/UInt32.html). Since the PCL2 message is a complex, and dynamic message type, I also had to initialize the memory for this message, for which I used the [Types Handling example](TODO) from last week.

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/sensor_vl53l5cx_i2c_portenta.jpg"/>
	<figcaption>The imaging sensor connected to the I2C pins on the Arduino Portenta.
	</figcaption>
</figure>

Now, since the [PCL library](https://pointclouds.org/) is not available on the Arduino, I couldn't use any of its utility functions to create a modifier and iterators to populate the message. This method is shown using ROS2 in [this video](https://www.youtube.com/watch?v=lTami8Igc3c) by [the Polyhobbyist](https://github.com/polyhobbyist) and the code can be found [https://github.com/polyhobbyist/ros_qwiic_tof](TODO). Since I am using micro-ROS, I instead had to computate and populate the message data myself. Here's how I did it: In the Integer Publisher example, the setup function defines an allocator, a node, a publisher, a timer and an executor using the [ROS2 Client Support Library](https://github.com/ros2/rcl/[) (rcl) and the [ROS2 Client Library package for C](https://github.com/ros2/rclc/) (rclc). The loop function is just two lines - the function call to [spin the executor](https://micro.ros.org/docs/concepts/client_library/execution_management/) and a small delay before the next loop. So, every time period, the executor is spun, which updates the timer, and the message is published from within the [timer callback](https://micro.ros.org/docs/tutorials/programming_rcl_rclc/executor/#callback). Since I need to poll the sensor and populate the PCL2 message at every time instance, I couldn't add all of this to the timer callback since it needs to be as quick as possible. Instead, I removed the timer and executor all together, and added the publisher function call directly at the end of the loop function. Now, in the setup function, I initialize the micro-ROS entities like before, and then initialize the message memory and fill in the static fields in the PCL2 message.

In the loop function, I first poll the sensor, compute the position of each sensor measurement (detection), and populate the dynamic fields of the PCL2 message. There were a few considerations to be made here - first the data from the sensor is an ordered array of [Float32](https://docs.ros.org/en/lunar/api/std_msgs/html/msg/Float32.html) values, with only depth measurements for each point on the 8x8 grid. First the position of each detection needs to be computed in the sensor's frame of reference. This can be done with some simple trigonometry, and results in x, y and z values for each detection on the grid. Next, since the data struct within the PCL2 message is a 1-dimensional array of type UInt8, the calculated position values (Float32, 4 bytes) need to be decomposed into four [UInt8](https://docs.ros.org/en/lunar/api/std_msgs/html/msg/UInt8.html) values (1 byte each) and then appended to the array. (Note: The calculated position values range between 0 and 4 meters, and if stored as integers in mm, the maximum value for each data point is 4000. This can fit in a [UInt16](https://docs.ros2.org/galactic/api/std_msgs/msg/UInt16.html) variable (2 bytes) instead of Float32, but apparently [RViz2](https://github.com/ros2/rviz) needs PointCloud2 messages to be of Float32 type as seen in [this](https://answers.ros.org/question/197309/rviz-does-not-display-pointcloud2-if-encoding-not-float32/) forum question, and [this](https://github.com/ros2/rviz/blob/rolling/rviz_default_plugins/src/rviz_default_plugins/displays/pointcloud/point_cloud2_display.cpp) source code.)

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/microros_portenta_vl53l5cx_wiring.jpg"/>
	<figcaption>The Portenta and the imaging sensor is attached to the Portenta Breakout which provides access to the ethernet connector. The ethernet cable is connected to the RPi on the AKROS robot. The USBC connection is provided only to power the setup.
	</figcaption>
</figure>

Now, only one field remains - the timestamp. For this, I used the [Time Sync example](https://github.com/micro-ROS/micro_ros_arduino/blob/galactic/examples/micro-ros_time_sync/micro-ros_time_sync.ino) to synchronize the time between the [micro-ROS agent](https://github.com/micro-ROS/micro-ROS-Agent) on the ROS2 side and the client on the Portenta. This is done in the loop function at every time period, and the resulting timestamp is then filled into the corresponding field in the header of the PCL2 message. Now, the message is populated and ready to be published. Once I was satisfied with the code, the next step was to test it with different transports using the RPi4 on the AKROS robot.

I decided to skip TCP and focus on only the transports I had tried so far - Serial and UDP over WiFi and Ethernet (using the [Portenta Breakout board](https://store-usa.arduino.cc/products/arduino-portenta-breakout)). Unfortunately, only the ethernet transport worked. For the other two, while the serial transport put Portenta in the error loop after working momentarily, the WiFi transport failed to even connect to the agent. At first I thought I had fried the WiFi chip on the Portenta, but I retried it with another example and it worked. I think the message size is too big and the WiFi and serial transports cannot handle it. It could also not work because of the removal of the timer and the executor. I will investigate this further when I have the time, but for the time being, I decided to continue with the UDP over Ethernet transport, as described in the last update.

### Visualization

Next, I wanted to visualize the sensor data. First, I decided to try with RViz2 - I launched the agent from my RPi4, then launched RViz and was immediately able to add and visualize the published PointCloud2. But this method is not only inconvenient since I need to connect the RPi to a screen, but also quite slow. Another method is to launch RViz2 from a different ROS2 PC over the same network, so I decided to the ROS2 installation I have on [WSL2](https://ubuntu.com/wsl). Unlike [WSL1](https://docs.microsoft.com/en-us/windows/wsl/compare-versions), WSL2 keeps its WLAN IP address hidden and it is not easily possible to access devices connected to the Windows 10 host. So, I decided to try and fix my [Foxglove Studio](https://foxglove.dev/docs/studio) setup, which on my first try few months ago, did not work with ROS2.

[![VL53L50X Pointcloud publisher using micro-ROS with Ethernet (RViz2)](https://adityakamath.github.io/assets/img/microros_vl53l5cx_rviz2_ss.PNG)](https://www.youtube.com/watch?v=8FGgY913k3Q "VL53L50X Pointcloud publisher using micro-ROS with Ethernet (RViz2)")

Foxglove is one of my favourite ROS tools when working on Windows. It allows me to open an app from the start menu, and visualize data streamed to/from my linux based ROS computers. I can do this without any complicated and time consuming setup. For ROS1, it connects to the rosmaster by setting the ROS_MASTER_URI and ROS_HOSTNAME environment variables on the RPi (as explained [here](http://wiki.ros.org/ROS/Tutorials/MultipleMachines)), and then it is defined in Foxglove on Windows. For ROS2, all the devices that talk on a network must be configured with the same ROS_DOMAIN_ID, as explained [here](https://roboticsbackend.com/ros2-multiple-machines-including-raspberry-pi/). Once again, this is an evironment variable that needs to be set on the RPi, and this needs to be defined in Foxglove. But this did not work either, I think that it is not just the environment variable, ROS2 also needs to be installed on Windows 10 for this to work. But maybe I'm wrong, I need to investigate this. Fortunately, Foxglove also has a [few other alternatives](https://foxglove.dev/docs/studio/connection/live-connection) - one of them being the [ROSBridge Suite](http://wiki.ros.org/rosbridge_suite), which works on both ROS and ROS2. As explained [here](https://foxglove.dev/docs/studio/connection/live-connection), I installed [rosbridge_suite](https://github.com/RobotWebTools/rosbridge_suite) on my RPi (I did it for both Noetic and Galactic, so I can use it for ROS1 as well), and ran the corresponding launch file on ROS2 which opens up a ROSBridge server. This lets networked computers access messages by simply connecting to the port of the ROSBridge server. This connection on the other hand was instant, and very reliable with quite low latency as seen in the video below:

[![VL53L50X Pointcloud publisher using micro-ROS with Ethernet (Foxglove Studio)](https://adityakamath.github.io/assets/img/microros_vl53l5cx_foxglove_ss.PNG)](https://www.youtube.com/watch?v=t7pT1snUXf8 "VL53L50X Pointcloud publisher using micro-ROS with Ethernet (Foxglove Studio)")

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/microros_portenta_vl53l5cx_viz.jpg"/>
	<figcaption>The PCL2 publisher, visualized using the Processing app, and Foxglove on Windows 10 - the left window shows the Processing app which uses the data received from the Portenta over the serial port. The screen on the right shows Foxglove Studio, which is visualizing sensor data from the ROS2 host using the ROSBridge Suite.</figcaption>
</figure>

### Other micro-ROS Changes

I also tried a few other things that are not functionally relevant but nice to have. First, I updated the ROS_DOMAIN_ID, which is set to 0 by default. On the RPi, it is quite easy, and is done by simply updating the environment variable. On the micro-ROS client side, it is not so straightforward. As explained in the micro-ROS [rcl/rclc tutorials](https://micro.ros.org/docs/tutorials/programming_rcl_rclc/node/), an ```init_options``` variable needs to be defined and then it is added to the initialization support using this function call: ```rclc_support_init_with_options(&support, 0, NULL, &init_options, &allocator)``` instead of ```rclc_support_init(&support, 0, NULL, &allocator)```. This is the recommended method for ROS2 Galactic and beyond, for ROS2 Foxy and earlier, there is a different method. With this working, I updated the bootup script to set the new ROS_DOMAIN_ID when the RPi boots up.

Next, I tried some additional examples. First, I decided to try the [Reconnection example](https://github.com/micro-ROS/micro_ros_arduino/blob/galactic/examples/micro-ros_reconnection_example/micro-ros_reconnection_example.ino) with the ethernet transport. Just like last week, it still did not work, but I was also unable to figure out the issue or find a fix. So, I opened an [issue](https://github.com/micro-ROS/micro_ros_arduino/issues/1072) on the [micro_ros_arduino](https://github.com/micro-ROS/micro_ros_arduino) repo explaining my analysis of the issue. I also have another [open issue](https://github.com/micro-ROS/micro_ros_arduino/issues/1065) there, for the failing ethernet transport on the Teensy 4.1. For this, I did receive a response already from one of the developers, turns out the ethernet transport was simply added by a contributor and not tested officially. So, this issue is still open for someone to investigate this further. It could also be me, but I need to find some time first.

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/microros_portenta_vl53l5cx_setup.jpg"/>
	<figcaption>The entire setup, connected to the AKROS robot via ethernet, and to the Windows laptop via USBC. The screens show the depth map visualization (as explained earlier)</figcaption>
</figure>

Finally, I decided to go through the [advanced micro-ROS tutorials](https://micro.ros.org/docs/tutorials/advanced/overview/). All of them are easy to understand and replicate, but to implement most of them I need to rebuild the micro-ROS libraries. Since I'm using pre-compiled libraries for now, I cannot proceed. So, I spent some time working on the AKROS2 robot. I will come back to these tutorials at a later time.

### AKROS(2) Updates

Like I mentioned in the last update, I found a way of making the robot more compact, while the laser scanner is still placed high enough for the beams not be obstructed by any part of the chassis. I only worked on the navigation module and the top base plate for now and the results look quite slick. I also decided to replace the 3D printed RPi case/cover with a [Flirc case for RPi4](https://flirc.tv/products/flirc-raspberrypi4-silver?variant=43085036454120), which uses its aluminium housing as a heat sink, and saves the space needed for a fan. It also looks really neat. The images below shows the new and old designs. I will try to 3D print and laser cut these new parts when I get the chance, but for now I intend to try out [PCBWay's 3D printing service](https://www.pcbway.com/rapid-prototyping/manufacture/?type=2&campaignid=12618070251&adgroupid=123589467481&feeditemid=&targetid=kwd-1059373875&loc_physical_ms=1010481&matchtype=p&network=g&device=c&devicemodel=&creative=510745073208&keyword=3d%20printing%20services&placement=&target=&adposition=&gclid=Cj0KCQjw8amWBhCYARIsADqZJoWo74bSuw-tF_K0gDioMSdxuWrjc7_G_yGzFYoEuZVuuq3N-Y5AHc8aAsgaEALw_wcB) when I place some PCB orders in the near future. While updating the 3D files, the [URDF](http://wiki.ros.org/urdf) of the robot also needs to be updated with the new meshes. While normally, I do it using an external monitor connected to the RPi, but I learnt of a much simpler version in [this week's ROS news](https://discourse.ros.org/t/ros-news-for-the-week-of-july-4th-2022/26422).

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/akros1_cad_right_final.PNG"/>
	<figcaption>Side view of the AKROS robot in its current state. It uses a 3D printed housing for the RPi, on top of which the LD06 laser scanner is placed. The LD06 is placed exactly in the middle of the robot's footprint.
	</figcaption>
</figure>

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/akros2_cad_right_1.PNG"/>
	<figcaption>In the new design, the LD06 laser scanner is moved ahead and is no longer in the center of the robot's footprint. The 3D printed housing is replaced by a Flirc case for the RPi4, which is quite compact and allows me to place the LD06 lower than it was. The new design is nearly 4cm shorter than the previous design. This allows me to use brass spacers of standard dimensions to add a layer on top, for maybe a GPS or UWB transciever, or to carry items around.
	</figcaption>
</figure>

It is called [jupyterlab-urdf](https://github.com/ihuicatl/jupyterlab-urdf), and is an extension for JupyterLab that allows users to create, edit and view URDFs from a browser. [Their documentation](https://jupyterlab-urdf.readthedocs.io/en/latest/) shows some [incredible examples](https://jupyterlab-urdf.readthedocs.io/en/latest/examples.html) of it working remotely on a browser, but it does not seem to work for me. The extension is installed and active, and I am also able to create and edit URDF files with a single button, but when I try the viewer, it shows me all the controls and settings, but a blank grid without any meshes. I haven't been able to find a solution yet, but I only spent about an hour on it, and since this project is new, its an understandable issue and will surely be fixed soon. I might also create an GitHub issue, but first I want to repeat the steps to confirm its not a problem in my installation.

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/akros2_blank_jupyterlab_urdf.PNG"/>
	<figcaption>The editor in jupyterlab-urdf, displaying a blank grid instead of meshes. I've correctly configured and sourced the ROS environment.
	</figcaption>
</figure>

### Next Steps

For the next week, maybe two, I want to focus on advanced micro-ROS topics - last week I mentioned that I was curious about the [micro-ROS concepts and architecture](https://micro.ros.org/docs/concepts/client_library/introduction/). This week, I also realized that I skipped the [rcl/rclc tutorials](https://micro.ros.org/docs/tutorials/programming_rcl_rclc/overview/) and missed a lot of important details. I want to try and practice these concepts hands-on instead of just reading them. Next, I want to implement another simple micro-ROS application. I have a [FlySky FS-i6x RC controller](https://www.flysky-cn.com/fsi6x) and I want to connect it to the Teensy 4.1 on the AKROS robot. This way, I can takeover from the autonomous navigation nodes and drive manually or do some course corrections during autonomous operation. I will also be able to drive the robot with the RC controller, without having the RPi switched on. I first need to connect the receiver to a level shifter, so that it can talk over serial at 3.3v. This, it gets connected to the [Teensy 4.1 expansion board](https://www.tindie.com/products/cburgess129/arduino-teensy41-teensy-41-expansion-board/) and its 3.3v UART TX/TX pins. Hopefully, there should be minimal noise and data loss during the voltage shift. Once a sample application is ready, I then intend to add micro-ROS features to it, so that I can publish twist messages back to the RPi4 from the Teensy on the AKROS2 robot. Meanwhile, I also received some of other the goodies I mentioned during the last post. One of them is the Flirc case I mentioned earlier, the second one is a [Wio Terminal](https://www.seeedstudio.com/wio-terminal-p-4509.html) (an impulse purchase when I saw it on discount, I still dont have a plan for it). I had also ordered [Qwiic](https://www.sparkfun.com/qwiic) connectors, alongside Qwiic adapters for the Wio Terminal's [Grove](https://wiki.seeedstudio.com/Grove_System/) connectors, and also for Portenta's Eslov self-identification port. The adapters were out of stock and I hope to receive them next week, along with my new Pico W board.

<figure class="aligncenter">
	<img src="https://adityakamath.github.io/assets/img/akros2_flirc_wio_terminal.jpg"/>
	<figcaption>The Flirc case for RPi4, along with the Wio Terminal (in white). The Wio terminal has a screen, buttons, a speaker, few sensors and Grove connectors for additional ones. It has a SAMD51 and wireless connectivity, so it can work by itself, but it also doubles up as a Raspberry Pi hat. Unfortunately, with the plastic casing, it does not fit on a Raspberry Pi 4, but fits perfectly onto a Raspberry Pi Zero. Now, I wait for the Pi Zero 2 W to be available, and I can maybe do some ROS things with it. Possibly use it for logging and diagnostics.
	</figcaption>
</figure>