---
layout: post
title: ROSCon 2022 - Kyoto ðŸ‡¯ðŸ‡µ
subtitle: My first ROSCon experience in the beautiful city of Kyoto
gh-repo: adityakamath/adityakamath.github.io
thumbnail-img: /assets/img/roscon2022_thumb.jpg
share-img: /assets/img/roscon2022_thumb.jpg
gh-badge: [follow]
comments: true
---

[Previous content remains the same...]

After lunch, the conference was broken into two tracks - Simulation and Tooling till the break, and Fleet Management and Deployment, till the end of the day. I chose to attend the Simulation track for the first half, and the Deployment track for the next few hours.

The Simulation track was quite interesting, mainly because I had only used [Gazebo](https://gazebosim.org/home) up till now, and always had issues with it. The talks in this track talked about new tools and techniques for robotics simulation with ROS - like [Unreal Engine](https://www.unrealengine.com/en-US/) for example. The talk by [Rapyuta Robotics](https://www.rapyuta-robotics.com/) focused mainly on leveraging existing technology from the gaming industry to build robot simulators - especially the photorealistic rendering capabilities and the accurate physics engines. The talk also included example architectures for a distributed simulator to simulate large numbers of robots and personal experiences of how Rapyuta Robotics uses these technologies for their business.

The next highlight for me was the talk from [Fraunhofer IPA](https://www.ipa.fraunhofer.de/en.html) about their model-based kinematics editor. The presenter, Harsh, talked about the need for [Model Driven Engineering](https://explainagile.com/agile/model-driven-engineering/) (MDE) in the ROS ecosystem. For someone with an electrical/mechanical engineering background, this resonated with me, as I'm more comfortable working in an MDE environment than writing code. Such tooling will only reduce the barrier to entry for non-software engineers into the world of robotics with ROS. Without it, ROS will only be an afterthought for some companies, where most robotics development still happens using tools like MATLAB/Simulink.

Before heading to a different hall for the Deployment track, I spent some more time in the exhibition area, checking out some more cool robots. First, I went to the [Luxonis](https://www.luxonis.com/) booth to get a look at their upcoming (now a [Kickstarter campaign](https://www.kickstarter.com/projects/opencv/rae-0)) robot called [Rae](https://spectrum.ieee.org/luxonis-rae-robot-kickstarter). A tiny, cute robot with differential drive and depth cameras on both sides. I also got a chance to see it driving around, and I must say, it is quite fast for its compact size.

![Luxonis Rae robot](/assets/img/roscon2022_rae.jpg)

Next, I headed to the [Husarion](https://husarion.com/) booth, where they had their new Mecanum wheeled robot on display. They let me drive the robot, but I nearly crashed it thanks to their joystick configuration, which was inverted as compared to the configuration I normally use. I also had a nice chat with the team, who I realized were all from Krakow, and [AGH University of Science and Technology](https://www.agh.edu.pl/en/), where I interned for a couple of months back in 2012. Good to know that AGH is still coming up with some amazing robots and robotics companies.

![Husarion robot](/assets/img/roscon2022_husarion.jpg)

Finally, we headed to the other hall, which was part of the original building (the morning sessions were in the 'New Hall', a massive space but quite modern and plain). This second venue was much more true to the original style of the building, with its unique brutalist architecture.

In the Deployment track, one of my highlights was the [ATOM Calibration Framework](https://www.sciencedirect.com/science/article/abs/pii/S0957417422012234), developed by researchers at the University of Aveiro. The calibration framework consists of multiple tools and scripts to calibrate a robot with multiple sensors and modalities, and then estimate transforms between these sensors and the robot hardware. The ATOM GitHub repository can be found [here](https://github.com/lardemua/atom).

Next, I saw a post from an engineer at [Bitcraze](https://www.bitcraze.io/) on the ROSCon app, who wanted to try out autonomous navigation using [Nav2](https://navigation.ros.org/) and their [Crazyflie 2.1 drone](https://www.bitcraze.io/products/old-products/crazyflie-2-0/) with a [multi-ToF sensor add-on](https://www.bitcraze.io/products/multi-ranger-deck/). Since I had already been to the ros2_control workshop, I decided to skip the talk and headed to the demo. Kimberly, the engineer who hosted the meetup gave an amazing demo of the tiny Crazyflie drone mapping the environment and then navigating using Nav2. I was amazed at how well the little drone operated, as just a few years ago (during my EngD program), our team of 12 had massive issues in just getting the drone flying.

![Bitcraze Crazyflie demo](/assets/img/roscon2022_crazyflie.jpg)

Finally, as the battery of the drone ran out, I headed back inside to listen to a talk about a real-life use case of ros2_control with [MoveIt 2](https://moveit.picknik.ai/humble/index.html). The talk focused on how [Picknik Robotics](https://picknik.ai/) (the developers of [MoveIt](https://moveit.ros.org/)) helped an optics manufacturing company upgrade their robot with ROS 2 Drivers, and the challenges they faced along the way. It was nice to hear of an actual use case of ros2_control after just learning how to use it just a day ago. Also nice to hear from a control engineer as most of the other talks seemed to be focused towards software engineers.

### Group Photo

Finally, at the end of Day 1, all participants were asked to assemble for a group photo. It did take a while as the photographer looked around for the perfect spot to capture 800+ roboticists from all over the world in a single frame. It was funny that there was no drone present in an auditorium full of roboticists. However, we ended up with an amazing photo.

![ROSCon 2022 Group Photo](/assets/img/roscon2022_group.jpg)